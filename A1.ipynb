{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "A1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiannanWei/UTS_ML2019_ID12998872/blob/master/A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Um89zp9qI8R",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Generative Adversarial Nets\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgA08IGVqI8S",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWT892OlqI8T",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1ylE-LGqI8U",
        "colab_type": "text"
      },
      "source": [
        "The future of deep learning is to explore and discover a variety of models that represent the patterns of data in the field of artificial intelligence, which tells people the information contained in the data, such as text information, audio information, image information and so on. Even the most successful of these deep learning models have encountered computational difficulties. The generative adversarial network model mentioned in the paper produces the expected output through the interactive game learning of at least two modules. \n",
        "For example, the generative model is similar to a gang of counterfeiters trying to produce and use counterfeit money, while the discriminative model is similar to the financial police finding and dealing with fake money. The generator continually spoofs the discriminator, which tries to resist the generator's spoofing. Because model training is alternately optimized, both models end up being indistinguishable from the real thing. \n",
        "In this paper, the authors propose a new modeling framework for generating models through antagonistic processes.  In this new modeling framework, two models are trained at the same time. One is the generation model G for capturing data distribution, and the another one which is discriminant model D for estimating the probability of samples from training data. G is trained to maximize the probability of D's error. This frame corresponds to a two-player game with a maximum setting and a lower limit. This method is used to prove that in the space of any function G and D, there exists a unique solution to make G reproduce the distribution of training data. In the case that G and D are defined by multilayer perceptrons, the whole system can be trained by back-propagation. During training or sample generation, no Markov chains or extended approximate inference networks are required. In this chapter, the author also conducts quantitative and qualitative evaluation of the generated samples through experiments, which proves the validity of this framework. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXQJGOpcqI8V",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTg_4tduqI8V",
        "colab_type": "text"
      },
      "source": [
        "The basic idea of GAN is to train two models G and D at the same time. The task of G is to generate samples that cannot be distinguished by D as much as possible, while the task of D is to distinguish real samples as much as possible. However, the author puts forward a special case of GAN. In this case, G adopts a multi-layer neural network with random noise as input, and D is also a multi-layer neural network. In each iteration, D trains k steps and G trains 1 step. Thus, if the update rate of G is slow enough, D will definitely converge to the best classification performance. However, at the beginning, since the data generated by G will be very poor, D can easily distinguish all the samples, which leads to the loss of training G is 0, thus preventing further in-depth learning. To this end, the author puts forward innovative solutions. The author solves this problem by changing the loss function. The following is a demonstration of GAN's training process provided by the author in the paper. Where z represents the random input noise, and the arrow above z represents the generation process of G, and the generated samples satisfy the distribution of the solid green line. The dotted black line shows the distribution of the actual sample. The blue dotted line represents the parameter updating process of G, so that the sample distribution generated by G is consistent with the actual sample distribution. \n",
        "\n",
        "![alt text](http://com88.com/GAN.PNG)\n",
        "\n",
        "The author innovatively improves the model framework so that the new method does not need a Markov chain and only USES backprop to obtain the gradient. An innovative model framework can include multiple functions, apply to various situations, and eliminate the need for reasoning. It allows the innovative modeling framework to overcome some computational difficulties. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwv9V3q0qI8W",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KvvVw0QqI8X",
        "colab_type": "text"
      },
      "source": [
        "Generally speaking, the quality of this paper is very high. The author introduces the theoretical basis of GAN in detail from the previous part and the results of their previous research work. Then through the mathematical equation and algorithm demonstration, the author's innovative model framework is described in detail. By comparing with other model frameworks, the author discusses the advantages and disadvantages of the author's model framework in detail, so that other researchers can have a comprehensive understanding of the author's research results. The author not only discusses the feasibility of the research through theory but also proves the feasibility of the research through practical experiments. MNIST, TFD and CIFAR-10 data sets are adopted to train the model, and some experimental results are provided to improve the reliability of the study. Although there are some shortcomings in the research results of the author, the author provides a link to the experimental code in the paper, so that relevant researchers can easily verify the reliability of the experimental results, and facilitate the subsequent improvement and in-depth research. At the end of the paper, the author puts forward some conclusions about the research results and provides some directions for further research. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59GK2-TzqI8Y",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v6W02sTqI8Z",
        "colab_type": "text"
      },
      "source": [
        "The application domain is appropriate for The GAN. As GAN is a generative model, it can be applied in some fields. For example, in specific application scenarios, such as the medical field, lack of training data is the biggest obstacle to using deep learning. GAN can generate more similar data, which can be added to the training set to improve the performance of the model. As a machine learning student, this paper is very interesting. It is only published in recent years, and its research content is relatively new, which will provide us with new knowledge and inspiration, and stimulate the interest of discussion. What is interesting about GAN is that it is a model of self-game, a bit like the training of competitive events in which two players compete to constantly stimulate their potential and improve their strength. It will play an increasingly important role in the field of deep learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4MvhAaQqI8a",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewMyKz8-qI8b",
        "colab_type": "text"
      },
      "source": [
        "The structure of this paper is very standard and the content is very complete. From the beginning of the abstract and introduction on the theoretical basis and content of the paper. Then the theoretical feasibility of the research is explained through the theory and results. Then the actual feasibility of the research is verified by practical experiments. The theory of the whole paper is rigorous, and proper use of mathematical equations and pseudo-code, and provide tables and images to illustrate the author's research more vividly. The author's description in the experiment section is slightly less.  Although the author provides the source code of the experiment, there is no detailed description of the experiment, which makes it difficult for some readers who want to redo the experiment. Overall, the paper is very good. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q487naRrqI8c",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "\n",
        "Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A.C., & Bengio, Y. 2014, \n",
        " 'Generative Adversarial Nets', Proceedings of NIPS, pp. 2672-2680.\n",
        "\n",
        "Krizhevsky, A., Sutskever, I., and Hinton, G. (2012). ImageNet classiﬁcation with deep convolutional neural networks. In NIPS’2012. \n",
        "\n",
        "Goodfellow, I. J., Warde-Farley, D., Lamblin, P., Dumoulin, V., Mirza, M., Pascanu, R., Bergstra, J., Bastien, F., and Bengio, Y. (2013c). Pylearn2: a machine learning research library. arXiv preprint arXiv:1308.4214."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlKwkMfchieQ",
        "colab_type": "text"
      },
      "source": [
        "**Link to repository:https://github.com/DiannanWei/UTS_ML2019_ID12998872**\n",
        "\n",
        "**Name: Diannan Wei**\n",
        "\n",
        "**Student ID: 12998872**"
      ]
    }
  ]
}